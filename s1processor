#This is a Python file
#Sabrina Barbaro 24/6/2020
#Let's try to make a processor
#First use the skeleton processorABC

from coffea import hist, processor
from coffea.analysis_objects import JaggedCandidateArray

class s1processor(processor.ProcessorABC):
    def __init__(self):                              #removed flag bc what is it?
        self._accumulator = processor.dict_accumulator({
            "sumw": processor.defaultdict_accumulator(float),
            "Jet": hist.Hist("#OfEvents", hist.Cat("dataset","NumOfCountsData"), hist.Bin("mass","InvariantMass",100,0,1000)),
            "b_Jet": hist.Hist("#OfEvents", hist.Cat("dataset","NumOfCountsData"),hist.Bin("bmass","InvariantMass",100,0,1000)),
        })                                                              #Add whatever variables you want here
                                                                        #hist.Hist documentation from https://coffeateam.github.io/coffea/api/coffea.hist.Hist.html

    @property                                                           #giving mea numba error, try running in coffea #Which worked
    def accumulator(self):
        return self._accumulator

    def process(self, df):
        output = self.accumulator.identity()

        dataset = df['dataset']
        #momentum = df['Jet_pt'].content,
        Jets= JaggedCandidateArray.candidatesfromcounts(
                df['nJet'],
                pt=df['Jet_pt'].content,
                eta=df['Jet_eta'].content,
                phi=df['Jet_phi'].content,
                mass=df['Jet_mass'].content,
                mayBe = df['Jet_isGoodBJet'].content,
                notB = df['Jet_isGoodJetAll'].content,)

        bcut = (Jets['mayBe']==1)
        bJets = Jets[bcut]
        ocut = ((Jets['mayBe']==0) & (Jets['notB']==1))
        oJets = Jets[ocut]
        
        #output["sumw"][dataset] += df.size
        output["Jet"].fill(dataset=dataset, mass=oJets.mass.flatten())
        output["b_Jet"].fill(dataset=dataset, bmass=bJets.mass.flatten())

        return output

    def postprocess(self, accumulator):
        return accumulator
   
from klepto.archives import dir_archive
from tW_scattering.Tools.helpers import *

###Follow Daniel's setup

def main():

        overwrite = True
        # load the config and the cache
        cfg = loadConfig()

        #Inputs are defined in a dictionary
        # dataset : list of files

        fileset = {
        'tW_scattering': glob.glob("/hadoop/cms/store/user/dspitzba/nanoAOD/ttw_samples/0p1p2/tW_scattering__nanoAOD/merged/*.root"),
        "TTW":           glob.glob("/hadoop/cms/store/user/dspitzba/nanoAOD/ttw_samples/0p1p2/TTWJetsToLNu_TuneCP5_13TeV-amcatnloFXFX-madspin-pythia8__RunIIAutumn18NanoAODv6-Nano25Oct2019_102X_upgrade2018_realistic_v20_ext1-v1/merged/*.root") \
                        + glob.glob("/hadoop/cms/store/user/dspitzba/nanoAOD/ttw_samples/0p1p2/TTWJetsToQQ_TuneCP5_13TeV-amcatnloFXFX-madspin-pythia8__RunIIAutumn18NanoAODv6-Nano25Oct2019_102X_upgrade2018_realistic_v20-v1/merged/*.root")
        }

        histograms = ["Jet", "b_Jet"]

        #initialize cache
        cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cfg['caches']['simpleProcessor']), serialized=True)
        if not overwrite:
            cache.load()

        if cfg == cache.get('cfg') and histograms == cache.get('histograms') and fileset == cache.get('fileset') and cache.get('simple_output'):
            output = cache.get('simple_output')
        else:
         output = processor.run_uproot_job(fileset,
                                      treename='Events',
                                      processor_instance=s1processor(),
                                      executor=processor.futures_executor,
                                      executor_args={'workers': 12, 'function_args': {'flatten': False}},
                                      chunksize=500000,
                                     )
        cache['fileset']        = fileset
        cache['cfg']            = cfg
        cache['histograms']     = histograms
        cache['simple_output']  = output
        cache.dump()

        #make plots
        outdir = "./tmp_plots"
        if not os.path.exists(outdir):
            os.makedirs(outdir)

        #for name in histograms:
         #   print (name)
          #  histogram = output[name]

        ax = hist.plot1d(output["b_Jet"],overlay="dataset", stack=True)
        ax.set_yscale('linear')
        ax.figure.savefig(os.path.join(outdir, "{}.pdf".format("b_Jet")))
        ax.clear()

           #ax = hist.plot1d(histogram, overlay="dataset", stack=False) 
           # ax.set_yscale('linear') # can be log
           # #ax.set_ylim(0,0.1)
           # ax.figure.savefig(os.path.join(outdir, "{}_shape.pdf".format(name)))
           # ax.clear()



        return output

if __name__ == "__main__":
    output = main()
